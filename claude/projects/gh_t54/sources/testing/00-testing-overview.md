# Testing Strategy Overview

**One-page summary for team discussions**

---

## Status Legend

This documentation includes patterns at different stages of adoption:

> **Status: Current** - Implemented; see existing code for examples.

> **Status: Planned** - Defined but not yet implemented.

> **Status: Potential** - An option we may adopt; not currently planned.

---

## The Problem We're Solving

Traditional approaches to testing in our previous repos suffered from:

- **Unclear purpose**: Tests existed but nobody knew if they were checking requirements or just implementation details
- **Maintenance burden**: Complex test data setups that broke whenever schemas changed
- **"Built on my machine"**: Local results didn't match CI, eroding trust
- **Coverage theater**: High coverage numbers with low confidence

## Our Approach: Purpose-Driven Testing

### The ARES Framework

Every test has a **primary purpose**. Knowing the purpose guides how we write, maintain, and respond to failures.

| Purpose | Question It Answers | Change Review Level |
|---------|--------------------|--------------------|
| **A**cceptance | Does this meet agreed requirements? | High: Team consensus |
| **R**egression | Did we accidentally break something? | Normal: Developer judgment |
| **E**xploration | What happens if I try this? | N/A: Not automated |
| **S**moke | Is the test infrastructure working? | Low: Rarely changes |

**When tests run**: All automated tests run on every push—PR or working branch.

**Who modifies tests**: Everyone (devs and AI agents). The difference is review rigor—acceptance test changes warrant team discussion (and realizing you might need to change them may signal to start discussions early); regression/smoke changes need normal code review to avoid spurious changes or loss of important coverage.

### File Naming Convention

> **Status: Current (convention defined, not yet fully applied)** - Existing tests may not follow these conventions yet.

**Vitest** (all end in `.test.ts`):
```
*.test.ts            → Regression (default)
*.spec.test.ts       → Acceptance
*.int.test.ts        → Integration
*.smoke.test.ts      → Smoke
```

**Other tools**:
```
*.stories.ts         → Storybook (colocated with components)
*.spec.ts (in e2e/)  → Playwright E2E
```

## Test Data: Builders & Scenarios

> **Status: Planned** - No builders implemented yet. See [03-builders-and-scenarios.md](./03-builders-and-scenarios.md) for design.

### Principle: Only Specify What's Special

```typescript
// Bad: Over-specified, brittle
const user = buildUser({
  id: 'user-123',
  email: 'test@example.com',
  firstName: 'John',
  role: 'admin',
  // ... every field
});

// Good: Intent is clear
const user = buildUser({ role: 'admin' });
```

### Principle: Scenarios as Code

Test setups that express *meaning*, not *exact data*. When schemas evolve, scenarios stay valid.

```typescript
function scenarioOrgWithManyStudents() {
  const org = buildOrganization();
  const students = buildUsers({ count: 1000, organizationId: org.id });
  return { org, students };
}
```

## Subjective and Non-Deterministic Testing

> **Status: Planned** - Golden datasets and large fixtures not yet implemented.

Not all outputs are objectively verifiable (AI analysis, transcription quality, QTF ratings).

**Golden Datasets**: Curated input/output pairs verified by domain experts. Used for:
- Acceptance/Regression: Outputs match (or approximate) golden outputs where it's possible to define closeness metrics (subjective in _degree_)
- Exploration: Starting points for manual investigation, with tools for automated running of the scenarios (but manual inspection of results) for cases where _correctness_ is subjective or results are too influenced by outside randomness to measure

**Large Fixtures**: Real transcript files that can't be generated by builders (or which have broad sections that aren't generated - swap out a name or a date, for instance, but the speech always stays the same for instance):
- Versioned and shared across test types
- Same fixtures support both automated tests and manual exploration

## CI/CD Integration

### Execution Order
```
Smoke → Unit → Integration/Component → E2E
```

### Package-Scoped Testing
Only run tests for packages affected by changes.  Ensure packages remain tightly scoped (e.g. avoid omni-packages that are often changed and require rebuilds of many dependencies) to avoid spurious runs.

### CI is Truth
CI results are authoritative. We want to reduce the variation in local runs (e.g. by having Docker-based local testing to match CI environments and maintaining similar reporters/similar sets of tests run).

## What Changes

| Before | After |
|--------|-------|
| Tests accumulate without pruning | Regression tests are disposable; acceptance tests are maintained |
| Test data copied/modified per test | Builders with reasonable defaults |
| Schema change = mass test updates | Versioned builders, scenarios survive changes |
| CI failures may be ignored | CI is the authority; flaky tests get fixed or removed |
| "It passed locally" | Docker-based local testing matches CI |

## Repo-Specific Focus

| Repo | Primary Testing Focus |
|------|----------------------|
| **SOA** | Library contracts, utility edge cases |
| **Thrive** | Processing pipelines, PII detection, QTF analysis |
| **Coach** | API contracts, authentication, user flows |

## Tooling

| Tool | Purpose |
|------|---------|
| **Vitest** | Unit/integration tests (backend and frontend utilities) |
| **Storybook** | Frontend component isolation, behavior testing, exploration |
| **Playwright** | E2E user journeys across pages |
| **Fishery** | Test data builders |
| **Supertest** | API endpoint testing |

### Frontend Testing Layers

> **Status: Planned** - Storybook not yet set up. Apply when frontend apps are in scope.

| Layer | Tool | Tests |
|-------|------|-------|
| Utility/Logic | Vitest | Pure functions, calculations (no DOM) |
| Component | Storybook + Vitest | Isolated component behavior, interactions |
| Journey | Playwright | Full user flows, auth, real API integration |

Storybook fills the gap between "no frontend testing" and "spin up the whole app for E2E"—it lets frontend devs test components like backend devs test services.

## Next Steps

1. Review the full documentation in `/docs/testing/`
2. Establish builders for core data types
3. Identify existing tests that should be acceptance vs regression
4. Set up CI pipeline with proper staging

---

*Full documentation: [README.md](./README.md)*
